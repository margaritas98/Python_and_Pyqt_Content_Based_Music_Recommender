{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center>Content-based music recommender</center></h1>\n",
    "\n",
    "## <center>Use a deep CNN and cosine similarity to recommend music</center>\n",
    "\n",
    "## <center>Step 4: Build a deep CNN using TFLEARN library and evaluate the model</center>\n",
    "\n",
    "\n",
    "## <center>Addition: Only changed to the parts that we have referred to the websites, the rest has been removed in compare with the original submission</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<<<<< Addition 1 >>>>>> added reference to the record function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function 1: to record a piece of music for play and further prediction.  \n",
    "\n",
    "The function to record audio to a wave file below was referred from Python pyaudio.Pyaudio() Examples. URL: https://www.programcreek.com/python/example/52624/pyaudio.PyAudio  \n",
    "\n",
    "The same function was used in the application file **'musicrecommender.py'** too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode(CHUNK=1024, FORMAT=pyaudio.paInt16, CHANNELS=2, RATE=44100,\n",
    "           RECORD_SECONDS=30, WAVE_OUTPUT_FILENAME=\"record.wav\"):\n",
    "    '''\n",
    "    :param CHUNK:  Frame per buffer size\n",
    "    :param FORMAT: Format of sample\n",
    "    :param CHANNELS: Channels number\n",
    "    :param RATE: Sample rate\n",
    "    :param RECORD_SECONDS: Record time\n",
    "    :param WAVE_OUTPUT_FILENAME: output file name and path\n",
    "    :return:\n",
    "    '''\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    frames = []\n",
    "    print \"* recording\"\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK, exception_on_overflow = False)\n",
    "        frames.append(data)\n",
    "    print \"* done recording\"\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<<<<< Addition 2 >>>>>> added reference to the DNN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function 5: to build a CNN model  \n",
    "\n",
    "The DNN model architecture code below was created based on Julien Despois, (2016). https://github.com/despoisj/DeepAudioClassification\n",
    "\n",
    "The same model construction function was used in the application files **'musicrecommender.py', 'testdnn.py'** and **'traindnn.py'** too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimization methods.\n",
    "sgd = tflearn.optimizers.SGD(learning_rate=0.01, lr_decay=0.96, decay_step=100)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "rmsprop = tflearn.optimizers.RMSProp(learning_rate=0.001, decay=0.999)\n",
    "adam = tflearn.optimizers.Adam(learning_rate=0.001, beta1=0.99)\n",
    "\n",
    "def createModel(nbClasses=8, imageSize1=128, imageSize2=431):\n",
    "    \n",
    "    print(\"[.] Creating DNN model\")\n",
    "    \n",
    "    convnet = input_data(shape=[None, imageSize1, imageSize2, 1], name='input')\n",
    "\n",
    "    convnet = conv_2d(convnet, 64, 2, activation='relu', weights_init=\"Xavier\")\n",
    "    convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "    convnet = conv_2d(convnet, 128, 2, activation='relu', weights_init=\"Xavier\")\n",
    "    convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "    convnet = conv_2d(convnet, 256, 2, activation='relu', weights_init=\"Xavier\")\n",
    "    convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "    convnet = conv_2d(convnet, 512, 2, activation='relu', weights_init=\"Xavier\")\n",
    "    convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "    convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "    convnet = dropout(convnet, 0.5)\n",
    "\n",
    "    convnet = fully_connected(convnet, nbClasses, activation='softmax')\n",
    "    convnet = regression(convnet, optimizer=adam, loss='categorical_crossentropy')\n",
    "    \n",
    "    music_model = tflearn.DNN(convnet)\n",
    "    \n",
    "    print(\"    Model created.\")\n",
    "\n",
    "    return music_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<<<<< Addition 3 >>>>>> Added reference part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference:  \n",
    "\n",
    "1, Julien Despois, (2016). https://github.com/despoisj/DeepAudioClassification  \n",
    "2, Python pyaudio.Pyaudio() examples. https://www.programcreek.com/python/example/52624/pyaudio.PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
